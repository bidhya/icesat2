{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to order the icesat-2 granules separately and download it after a while (few hours). That way we do not have to wait for order to be finished on the NSIDC Server\n",
    "\n",
    "Obervation: Usually an extra order is returned by the script that is not actually data  \n",
    "            Perhaps this was the known error on part of NSIDC  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following file need to be downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other custom modules specific to icesat-2\n",
    "from icesat2_search_and_download_ATL import  move_files_from_order, read_atl06, read_atl08, get_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success getting authentication\n"
     ]
    }
   ],
   "source": [
    "#Create session to store cookie and pass credentials to capabilities url\n",
    "# email = '' #no required here because we are just downloading the data \n",
    "try:\n",
    "    #from icesat2_search_and_download_ATL import get_api_key\n",
    "    uid, pswd, token = get_api_key()\n",
    "    print(\"Success getting authentication\")\n",
    "except:\n",
    "    # Input explicitly here\n",
    "    uid = ''#'Replace with your username'\n",
    "    pswd = ''#'Repalce with your password'\n",
    "    #pswd = getpass.getpass('Earthdata Login password: ') #B2f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/icesat2/rema/region_03_peninsula_south_3/WV01_20181109_102001007A212700_102001007B433700_2m_lsf True\n",
      "5000000454814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Extraction Error (SHUTIL): perhaps file already exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end: 5000000454814\n"
     ]
    }
   ],
   "source": [
    "# base_icesat2_path = f'D:/icesat2/{dem_type}/{region}_2' #temp testing only\n",
    "''' Download the previously ordered icesat2 data and extract zip files\n",
    "    The order is read from the order.csv file saved earlier in the same folder as order\n",
    "'''\n",
    "# Define the path for download path\n",
    "base_icesat2_path = 'D:/icesat2/rema/region_03_peninsula_south_3' #change based on region\n",
    "# Read the csv file with order numbers\n",
    "df = pd.read_csv(f'{base_icesat2_path}/orders.csv', index_col=0)\n",
    "for idx, ser in df.iterrows():\n",
    "    #print(idx, ser.values)\n",
    "    orderIDs = list(ser.values)\n",
    "    strip = idx\n",
    "    icesat2_path = base_icesat2_path + '/' + strip\n",
    "    print(icesat2_path, os.path.exists(icesat2_path))\n",
    "    for orderID in orderIDs:\n",
    "        try:\n",
    "            print(orderID)\n",
    "            downloadURL = f'https://n5eil02u.ecs.nsidc.org/esir/{orderID}.zip'\n",
    "            # Create session to store cookie and pass credentials to capabilities url\n",
    "            # session = requests.session() # being deprecated but still used by nsidc\n",
    "            session = requests.sessions.Session() #newer\n",
    "            s = session.get(downloadURL) #Required But still 401 Error\n",
    "            zip_response = session.get(s.url, auth=(uid,pswd))\n",
    "            # zip_response = session.get(downloadURL, auth=(uid,pswd)) #But this does not work\n",
    "            zip_response.raise_for_status()\n",
    "\n",
    "            #icesat2_path = 'D:/temp'\n",
    "            with zipfile.ZipFile(io.BytesIO(zip_response.content)) as z:\n",
    "                z.extractall(f'{icesat2_path}/downloads')\n",
    "            # Extract files from downloads folder and remove the downloads folder\n",
    "            move_files_from_order(icesat2_path)\n",
    "            print('end:', orderID)\n",
    "        except:\n",
    "            print(f'Missing {orderID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn warnings off\n",
    "# import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fiona._env:Normalized/laundered field name: 'h_te_best_fit' to 'h_te_best_'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_te_interp' to 'h_te_inter'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_te_median' to 'h_te_media'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_te_uncertainty' to 'h_te_uncer'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'n_te_photons' to 'n_te_photo'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'terrain_slope' to 'terrain_sl'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'canopy_flag' to 'canopy_fla'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'canopy_openness' to 'canopy_ope'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'canopy_rh_conf' to 'canopy_rh_'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'centroid_height' to 'centroid_h'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_canopy_abs' to 'h_canopy_a'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_canopy_quad' to 'h_canopy_q'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_canopy_uncertainty' to 'h_canopy_u'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_dif_canopy' to 'h_dif_cano'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_max_canopy' to 'h_max_cano'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_max_canopy_abs' to 'h_max_ca_1'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_mean_canopy' to 'h_mean_can'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_mean_canopy_abs' to 'h_mean_c_1'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_median_canopy' to 'h_median_c'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_median_canopy_abs' to 'h_median_1'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_min_canopy' to 'h_min_cano'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'h_min_canopy_abs' to 'h_min_ca_1'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'landsat_flag' to 'landsat_fl'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'landsat_perc' to 'landsat_pe'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'n_ca_photons' to 'n_ca_photo'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'n_toc_photons' to 'n_toc_phot'\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'toc_roughness' to 'toc_roughn'\n"
     ]
    }
   ],
   "source": [
    "# Parse the downloaded HDF Files (ATL06 or ATL08)\n",
    "read_atl08(icesat2_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
